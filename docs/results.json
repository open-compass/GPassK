{
    "Llama-3.1-8B-Instruct": {
        "link": "https://huggingface.co/meta-llama/Llama-3.1-8B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 24.0,
            "LiveMathBench-Hard-2412": 2.2,
            "MATH500-L5": 26.1,
            "AIME2024-45": 4.4,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 18.2,
            "LiveMathBench-Hard-2412": 0.8,
            "MATH500-L5": 17.8,
            "AIME2024-45": 2.2,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 11.3,
            "LiveMathBench-Hard-2412": 0.0,
            "MATH500-L5": 10.7,
            "AIME2024-45": 1.6,
            "AIME2025": 0.0
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 4.55,
            "LiveMathBench-Hard-2412": 0.0,
            "MATH500-L5": 3.5,
            "AIME2024-45": 0.0,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 10.4,
            "LiveMathBench-Hard-2412": 0.0,
            "MATH500-L5": 9.7,
            "AIME2024-45": 1.2,
            "AIME2025": 0.0
        }
    },
    "Llama-3.1-70B-Instruct": {
        "link": "https://huggingface.co/meta-llama/Llama-3.1-70B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 29.8,
            "LiveMathBench-Hard-2412": 4.4,
            "MATH500-L5": 39.6,
            "AIME2024-45": 15.6,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 30.0,
            "LiveMathBench-Hard-2412": 12.3,
            "MATH500-L5": 41.8,
            "AIME2024-45": 15.0,
            "AIME2025": 4.6
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 22.2,
            "LiveMathBench-Hard-2412": 7.4,
            "MATH500-L5": 32.1,
            "AIME2024-45": 8.1,
            "AIME2025": 0.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 12.5,
            "LiveMathBench-Hard-2412": 2.7,
            "MATH500-L5": 16.1,
            "AIME2024-45": 3.0,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 20.8,
            "LiveMathBench-Hard-2412": 6.9,
            "MATH500-L5": 29.3,
            "AIME2024-45": 8.0,
            "AIME2025": 0.7
        }
    },
    "Llama-3.3-70B-Instruct": {
        "link": "https://huggingface.co/meta-llama/Llama-3.3-70B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 40.3,
            "LiveMathBench-Hard-2412": 4.4,
            "MATH500-L5": 54.5,
            "AIME2024-45": 22.2,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 36.2,
            "LiveMathBench-Hard-2412": 7.8,
            "MATH500-L5": 55.4,
            "AIME2024-45": 25.3,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 28.9,
            "LiveMathBench-Hard-2412": 4.8,
            "MATH500-L5": 49.5,
            "AIME2024-45": 18.2,
            "AIME2025": 6.6
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 19.1,
            "LiveMathBench-Hard-2412": 2.4,
            "MATH500-L5": 35.0,
            "AIME2024-45": 6.9,
            "AIME2025": 0.5
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 27.5,
            "LiveMathBench-Hard-2412": 4.6,
            "MATH500-L5": 47.3,
            "AIME2024-45": 16.4,
            "AIME2025": 5.0
        }
    },
    "Qwen2.5-7B-Instruct": {
        "link": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 37.0,
            "LiveMathBench-Hard-2412": 13.3,
            "MATH500-L5": 56.0,
            "AIME2024-45": 11.1,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 36.5,
            "LiveMathBench-Hard-2412": 6.2,
            "MATH500-L5": 54.9,
            "AIME2024-45": 8.9,
            "AIME2025": 9.7
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 27.2,
            "LiveMathBench-Hard-2412": 3.2,
            "MATH500-L5": 43.3,
            "AIME2024-45": 8.1,
            "AIME2025": 6.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 16.0,
            "LiveMathBench-Hard-2412": 2.2,
            "MATH500-L5": 28.0,
            "AIME2024-45": 4.7,
            "AIME2025": 0.2
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 25.8,
            "LiveMathBench-Hard-2412": 3.3,
            "MATH500-L5": 41.5,
            "AIME2024-45": 7.5,
            "AIME2025": 4.7
        }
    },
    "Qwen2.5-32B-Instruct": {
        "link": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 50.8,
            "LiveMathBench-Hard-2412": 13.3,
            "MATH500-L5": 64.2,
            "AIME2024-45": 11.1,
            "AIME2025": 20.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 48.3,
            "LiveMathBench-Hard-2412": 14.1,
            "MATH500-L5": 66.6,
            "AIME2024-45": 7.1,
            "AIME2025": 11.5
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 39.5,
            "LiveMathBench-Hard-2412": 10.5,
            "MATH500-L5": 59.4,
            "AIME2024-45": 3.4,
            "AIME2025": 0.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 28.6,
            "LiveMathBench-Hard-2412": 3.5,
            "MATH500-L5": 46.0,
            "AIME2024-45": 2.2,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 38.1,
            "LiveMathBench-Hard-2412": 9.1,
            "MATH500-L5": 57.4,
            "AIME2024-45": 3.7,
            "AIME2025": 1.4
        }
    },
    "Qwen2.5-72B-Instruct": {
        "link": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 51.7,
            "LiveMathBench-Hard-2412": 17.8,
            "MATH500-L5": 63.4,
            "AIME2024-45": 13.3,
            "AIME2025": 20.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 47.3,
            "LiveMathBench-Hard-2412": 15.3,
            "MATH500-L5": 62.5,
            "AIME2024-45": 13.7,
            "AIME2025": 12.2
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 39.6,
            "LiveMathBench-Hard-2412": 11.3,
            "MATH500-L5": 54.4,
            "AIME2024-45": 12.9,
            "AIME2025": 5.8
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 29.0,
            "LiveMathBench-Hard-2412": 5.4,
            "MATH500-L5": 44.9,
            "AIME2024-45": 7.5,
            "AIME2025": 0.1
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 37.8,
            "LiveMathBench-Hard-2412": 10.5,
            "MATH500-L5": 53.1,
            "AIME2024-45": 11.7,
            "AIME2025": 4.9
        }
    },
    "DeepSeek-V3.0-Chat": {
        "link": "https://github.com/deepseek-ai/DeepSeek-V3",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": "55.0",
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": null
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": "59.5",
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": null
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": "49.9",
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": null
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": "35.0",
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": null
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": "47.9",
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": null
        }
    },
    "Mistral-Large-Instruct-2411-123B": {
        "link": "https://example.com/mistral",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 41.6,
            "LiveMathBench-Hard-2412": 13.3,
            "MATH500-L5": 56.0,
            "AIME2024-45": 13.3,
            "AIME2025": 13.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 39.4,
            "LiveMathBench-Hard-2412": 13.3,
            "MATH500-L5": 52.7,
            "AIME2024-45": 15.6,
            "AIME2025": 10.8
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 37.1,
            "LiveMathBench-Hard-2412": 12.1,
            "MATH500-L5": 50.4,
            "AIME2024-45": 15.6,
            "AIME2025": 6.8
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 32.9,
            "LiveMathBench-Hard-2412": 9.0,
            "MATH500-L5": 45.2,
            "AIME2024-45": 15.6,
            "AIME2025": 6.7
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 36.4,
            "LiveMathBench-Hard-2412": 11.4,
            "MATH500-L5": 49.5,
            "AIME2024-45": 15.6,
            "AIME2025": 7.2
        }
    },
    "Gemini-1.5-Pro-Latest": {
        "link": "https://ai.google.dev/gemini-api/docs/models/gemini",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 59.1,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 20.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 55.9,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 10.8
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 47.3,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 6.7
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 31.0,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 4.4
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 44.3,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 6.8
        }
    },
    "Gemini-2.0-Flash-Exp": {
        "link": "https://ai.google.dev/gemini-api/docs/models/gemini",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": null,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 79.1,
            "AIME2024-45": 33.3,
            "AIME2025": 26.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": null,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 83.3,
            "AIME2024-45": 28.4,
            "AIME2025": 23.1
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": null,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 76.3,
            "AIME2024-45": 22.5,
            "AIME2025": 20.0
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": null,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 63.1,
            "AIME2024-45": 10.6,
            "AIME2025": 20.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": null,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 74.1,
            "AIME2024-45": 20.5,
            "AIME2025": 20.3
        }
    },
    "Claude-3.5-Sonnet": {
        "link": "https://docs.anthropic.com/claude/docs/models-overview",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 46.7,
            "LiveMathBench-Hard-2412": 11.1,
            "MATH500-L5": 50.0,
            "AIME2024-45": 13.3,
            "AIME2025": 13.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 44.1,
            "LiveMathBench-Hard-2412": 9.6,
            "MATH500-L5": 52.6,
            "AIME2024-45": 11.5,
            "AIME2025": 6.4
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 36.2,
            "LiveMathBench-Hard-2412": 3.3,
            "MATH500-L5": 42.4,
            "AIME2024-45": 5.9,
            "AIME2025": 1.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 26.6,
            "LiveMathBench-Hard-2412": 0.0,
            "MATH500-L5": 25.6,
            "AIME2024-45": 2.4,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 35.3,
            "LiveMathBench-Hard-2412": 3.3,
            "MATH500-L5": 39.9,
            "AIME2024-45": 5.6,
            "AIME2025": 1.7
        }
    },
    "GPT-4o-2024-11-20": {
        "link": "https://openai.com/index/gpt-4o-system-card/",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 44.8,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 52.9,
            "AIME2024-45": 8.5,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 41.9,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 53.1,
            "AIME2024-45": 7.4,
            "AIME2025": 0.1
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 32.9,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 41.9,
            "AIME2024-45": 4.5,
            "AIME2025": 0.0
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 22.2,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 21.5,
            "AIME2024-45": 1.1,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 31.6,
            "LiveMathBench-Hard-2412": null,
            "MATH500-L5": 38.3,
            "AIME2024-45": 4.2,
            "AIME2025": 0.0
        }
    },
    "DeepSeek-Math-7B-RL": {
        "link": "https://github.com/deepseek-ai/DeepSeek-Math",
        "opensourced": "TRUE",
        "mathLM": "TRUE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 23.5,
            "LiveMathBench-Hard-2412": 8.9,
            "MATH500-L5": 15.7,
            "AIME2024-45": 0.0,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 19.8,
            "LiveMathBench-Hard-2412": 3.8,
            "MATH500-L5": 15.6,
            "AIME2024-45": 1.5,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 14.0,
            "LiveMathBench-Hard-2412": 2.2,
            "MATH500-L5": 8.7,
            "AIME2024-45": 0.0,
            "AIME2025": 0.0
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 9.7,
            "LiveMathBench-Hard-2412": 0.1,
            "MATH500-L5": 5.7,
            "AIME2024-45": 0.0,
            "AIME2025": 0.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 13.7,
            "LiveMathBench-Hard-2412": 1.8,
            "MATH500-L5": 9.0,
            "AIME2024-45": 0.1,
            "AIME2025": 0.0
        }
    },
    "NuminaMath-72B-CoT": {
        "link": "https://huggingface.co/AI-MO/NuminaMath-72B-CoT",
        "opensourced": "TRUE",
        "mathLM": "TRUE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 40.8,
            "LiveMathBench-Hard-2412": 11.1,
            "MATH500-L5": 41.0,
            "AIME2024-45": 2.2,
            "AIME2025": 0.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 34.0,
            "LiveMathBench-Hard-2412": 8.8,
            "MATH500-L5": 36.8,
            "AIME2024-45": 2.9,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 27.1,
            "LiveMathBench-Hard-2412": 7.2,
            "MATH500-L5": 26.8,
            "AIME2024-45": 2.2,
            "AIME2025": 6.7
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 14.2,
            "LiveMathBench-Hard-2412": 5.1,
            "MATH500-L5": 16.7,
            "AIME2024-45": 0.1,
            "AIME2025": 4.4
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 25.0,
            "LiveMathBench-Hard-2412": 7.1,
            "MATH500-L5": 25.6,
            "AIME2024-45": 1.6,
            "AIME2025": 6.4
        }
    },
    "Qwen2.5-Math-7B-Instruct": {
        "link": "https://huggingface.co/Qwen/Qwen2.5-Math-7B-Instruct",
        "opensourced": "TRUE",
        "mathLM": "TRUE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 44.1,
            "LiveMathBench-Hard-2412": 15.6,
            "MATH500-L5": 65.7,
            "AIME2024-45": 13.3,
            "AIME2025": 6.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 44.1,
            "LiveMathBench-Hard-2412": 9.3,
            "MATH500-L5": 65.0,
            "AIME2024-45": 4.6,
            "AIME2025": 9.7
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 38.3,
            "LiveMathBench-Hard-2412": 4.4,
            "MATH500-L5": 62.2,
            "AIME2024-45": 2.6,
            "AIME2025": 6.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 28.1,
            "LiveMathBench-Hard-2412": 2.2,
            "MATH500-L5": 57.6,
            "AIME2024-45": 2.2,
            "AIME2025": 0.2
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 36.6,
            "LiveMathBench-Hard-2412": 4.6,
            "MATH500-L5": 61.5,
            "AIME2024-45": 2.8,
            "AIME2025": 4.7
        }
    },
    "Qwen2.5-Math-72B-Instruct": {
        "link": "https://huggingface.co/Qwen/Qwen2.5-Math-72B-Instruct",
        "opensourced": "TRUE",
        "mathLM": "TRUE",
        "o1-like": "FALSE",
        "Greedy": {
            "LiveMathBench-2412": 57.6,
            "LiveMathBench-Hard-2412": 11.1,
            "MATH500-L5": 71.6,
            "AIME2024-45": 20.0,
            "AIME2025": 13.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 52.7,
            "LiveMathBench-Hard-2412": 13.2,
            "MATH500-L5": 64.9,
            "AIME2024-45": 18.7,
            "AIME2025": 7.0
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 45.4,
            "LiveMathBench-Hard-2412": 9.7,
            "MATH500-L5": 59.4,
            "AIME2024-45": 16.2,
            "AIME2025": 6.7
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 27.9,
            "LiveMathBench-Hard-2412": 5.6,
            "MATH500-L5": 46.0,
            "AIME2024-45": 6.7,
            "AIME2025": 4.4
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 42.3,
            "LiveMathBench-Hard-2412": 9.1,
            "MATH500-L5": 57.4,
            "AIME2024-45": 14.1,
            "AIME2025": 6.4
        }
    },
    "Skywork-o1-8B": {
        "link": "https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 45.4,
            "LiveMathBench-Hard-2412": 20.0,
            "MATH500-L5": 61.2,
            "AIME2024-45": 11.1,
            "AIME2025": 13.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 39.3,
            "LiveMathBench-Hard-2412": 14.0,
            "MATH500-L5": 56.5,
            "AIME2024-45": 11.2,
            "AIME2025": 15.3
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 31.9,
            "LiveMathBench-Hard-2412": 11.1,
            "MATH500-L5": 52.2,
            "AIME2024-45": 10.3,
            "AIME2025": 13.3
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 21.7,
            "LiveMathBench-Hard-2412": 7.4,
            "MATH500-L5": 42.9,
            "AIME2024-45": 1.5,
            "AIME2025": 7.2
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 30.4,
            "LiveMathBench-Hard-2412": 10.6,
            "MATH500-L5": 50.7,
            "AIME2024-45": 8.2,
            "AIME2025": 11.8
        }
    },
    "QwQ-32B-Preview": {
        "link": "https://huggingface.co/Qwen/QwQ-32B-Preview",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 72.7,
            "LiveMathBench-Hard-2412": 15.6,
            "MATH500-L5": 82.8,
            "AIME2024-45": 44.4,
            "AIME2025": 26.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 74.9,
            "LiveMathBench-Hard-2412": 5.4,
            "MATH500-L5": 86.7,
            "AIME2024-45": 43.7,
            "AIME2025": 34.5
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 65.8,
            "LiveMathBench-Hard-2412": 3.5,
            "MATH500-L5": 78.3,
            "AIME2024-45": 32.1,
            "AIME2025": 32.4
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 40.1,
            "LiveMathBench-Hard-2412": 2.2,
            "MATH500-L5": 60.0,
            "AIME2024-45": 15.3,
            "AIME2025": 15.6
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 61.2,
            "LiveMathBench-Hard-2412": 3.3,
            "MATH500-L5": 75.7,
            "AIME2024-45": 29.3,
            "AIME2025": 28.1
        }
    },
    "OpenAI o1-mini": {
        "link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 74.1,
            "LiveMathBench-Hard-2412": 18.4,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 46.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 76.3,
            "LiveMathBench-Hard-2412": 21.0,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 39.9
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 67.3,
            "LiveMathBench-Hard-2412": 10.1,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 32.5
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 48.3,
            "LiveMathBench-Hard-2412": 0.5,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 14.0
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 64.8,
            "LiveMathBench-Hard-2412": 8.5,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 28.4
        }
    },
    "OpenAI o3-mini": {
        "link": "https://openai.com/index/openai-o3-mini/",
        "opensourced": "FALSE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 84.7,
            "LiveMathBench-Hard-2412": 43.3,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 53.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 85.7,
            "LiveMathBench-Hard-2412": 47.4,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 59.0
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 78.8,
            "LiveMathBench-Hard-2412": 32.5,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 46.5
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 65.3,
            "LiveMathBench-Hard-2412": 7.7,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 29.4
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 76.8,
            "LiveMathBench-Hard-2412": 28.6,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 43.6
        }
    },
    "DeepSeek Distill Qwen-1.5B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 42.4,
            "LiveMathBench-Hard-2412": 6.7,
            "MATH500-L5": 38.8,
            "AIME2024-45": 20.0,
            "AIME2025": 26.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 61.9,
            "LiveMathBench-Hard-2412": 7.8,
            "MATH500-L5": 72.5,
            "AIME2024-45": 24.4,
            "AIME2025": 31.9
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 48.8,
            "LiveMathBench-Hard-2412": 2.5,
            "MATH500-L5": 61.9,
            "AIME2024-45": 16.6,
            "AIME2025": 23.8
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 25.6,
            "LiveMathBench-Hard-2412": 0.1,
            "MATH500-L5": 34.9,
            "AIME2024-45": 2.0,
            "AIME2025": 1.4
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 45.1,
            "LiveMathBench-Hard-2412": 2.5,
            "MATH500-L5": 57.4,
            "AIME2024-45": 13.7,
            "AIME2025": 18.6
        }
    },
    "DeepSeek Distill Qwen-7B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 65.6,
            "LiveMathBench-Hard-2412": 17.8,
            "MATH500-L5": 79.1,
            "AIME2024-45": 42.2,
            "AIME2025": 46.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 73.0,
            "LiveMathBench-Hard-2412": 11.8,
            "MATH500-L5": 88.7,
            "AIME2024-45": 59.3,
            "AIME2025": 46.6
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 66.4,
            "LiveMathBench-Hard-2412": 4.7,
            "MATH500-L5": 80.9,
            "AIME2024-45": 34.1,
            "AIME2025": 38.3
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 48.4,
            "LiveMathBench-Hard-2412": 0.4,
            "MATH500-L5": 63.4,
            "AIME2024-45": 15.3,
            "AIME2025": 22.7
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 63.1,
            "LiveMathBench-Hard-2412": 4.5,
            "MATH500-L5": 78.4,
            "AIME2024-45": 32.9,
            "AIME2025": 36.1
        }
    },
    "DeepSeek Distill Qwen-14B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 69.8,
            "LiveMathBench-Hard-2412": 15.6,
            "MATH500-L5": 76.1,
            "AIME2024-45": 60.0,
            "AIME2025": 46.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 79.9,
            "LiveMathBench-Hard-2412": 21.3,
            "MATH500-L5": 91.1,
            "AIME2024-45": 75.8,
            "AIME2025": 58.8
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 71.2,
            "LiveMathBench-Hard-2412": 9.9,
            "MATH500-L5": 86.1,
            "AIME2024-45": 63.7,
            "AIME2025": 41.4
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 51.6,
            "LiveMathBench-Hard-2412": 1.3,
            "MATH500-L5": 69.0,
            "AIME2024-45": 25.3,
            "AIME2025": 25.2
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 68.0,
            "LiveMathBench-Hard-2412": 9.3,
            "MATH500-L5": 82.9,
            "AIME2024-45": 56.5,
            "AIME2025": 40.8
        }
    },
    "DeepSeek Distill Qwen-32B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 67.7,
            "LiveMathBench-Hard-2412": 22.2,
            "MATH500-L5": 83.6,
            "AIME2024-45": 64.4,
            "AIME2025": 33.3
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 81.2,
            "LiveMathBench-Hard-2412": 27.9,
            "MATH500-L5": 89.5,
            "AIME2024-45": 77.3,
            "AIME2025": 59.7
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 72.3,
            "LiveMathBench-Hard-2412": 10.9,
            "MATH500-L5": 84.2,
            "AIME2024-45": 63.9,
            "AIME2025": 50.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 54.5,
            "LiveMathBench-Hard-2412": 1.7,
            "MATH500-L5": 71.4,
            "AIME2024-45": 33.6,
            "AIME2025": 29.5
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 69.7,
            "LiveMathBench-Hard-2412": 10.9,
            "MATH500-L5": 82.3,
            "AIME2024-45": 58.1,
            "AIME2025": 47.3
        }
    },
    "DeepSeek Distill Llama-8B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 58.4,
            "LiveMathBench-Hard-2412": 8.9,
            "MATH500-L5": 65.7,
            "AIME2024-45": 40.0,
            "AIME2025": 40.0
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 67.8,
            "LiveMathBench-Hard-2412": 12.6,
            "MATH500-L5": 79.3,
            "AIME2024-45": 53.7,
            "AIME2025": 40.4
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 56.8,
            "LiveMathBench-Hard-2412": 3.3,
            "MATH500-L5": 70.2,
            "AIME2024-45": 33.8,
            "AIME2025": 21.2
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 31.9,
            "LiveMathBench-Hard-2412": 0.0,
            "MATH500-L5": 43.6,
            "AIME2024-45": 9.4,
            "AIME2025": 7.9
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 52.2,
            "LiveMathBench-Hard-2412": 3.8,
            "MATH500-L5": 65.4,
            "AIME2024-45": 29.9,
            "AIME2025": 21.0
        }
    },
    "DeepSeek Distill Llama-70B": {
        "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 74.8,
            "LiveMathBench-Hard-2412": 35.6,
            "MATH500-L5": 87.3,
            "AIME2024-45": 60.0,
            "AIME2025": 46.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 80.8,
            "LiveMathBench-Hard-2412": 29.8,
            "MATH500-L5": 90.3,
            "AIME2024-45": 72.5,
            "AIME2025": 52.5
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 73.0,
            "LiveMathBench-Hard-2412": 16.3,
            "MATH500-L5": 86.3,
            "AIME2024-45": 65.0,
            "AIME2025": 38.6
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 53.0,
            "LiveMathBench-Hard-2412": 5.0,
            "MATH500-L5": 69.1,
            "AIME2024-45": 33.3,
            "AIME2025": 26.8
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 69.7,
            "LiveMathBench-Hard-2412": 15.1,
            "MATH500-L5": 82.9,
            "AIME2024-45": 58.2,
            "AIME2025": 37.4
        }
    },
    "DeepSeek R1": {
        "link": "https://github.com/deepseek-ai/DeepSeek-R1",
        "opensourced": "TRUE",
        "mathLM": "FALSE",
        "o1-like": "TRUE",
        "Greedy": {
            "LiveMathBench-2412": 81.1,
            "LiveMathBench-Hard-2412": 42.2,
            "MATH500-L5": 91.8,
            "AIME2024-45": 77.8,
            "AIME2025": 66.7
        },
        "G-Pass@16-0.5": {
            "LiveMathBench-2412": 83.6,
            "LiveMathBench-Hard-2412": 46.6,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 52.6
        },
        "G-Pass@16-0.75": {
            "LiveMathBench-2412": 79.1,
            "LiveMathBench-Hard-2412": 33.6,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 46.8
        },
        "G-Pass@16-1.0": {
            "LiveMathBench-2412": 69.5,
            "LiveMathBench-Hard-2412": 9.8,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 24.3
        },
        "mG-Pass@16": {
            "LiveMathBench-2412": 77.6,
            "LiveMathBench-Hard-2412": 29.6,
            "MATH500-L5": null,
            "AIME2024-45": null,
            "AIME2025": 42.5
        }
    }
}